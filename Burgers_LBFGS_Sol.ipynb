{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_LBFGS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Burgers Equation\n",
        "Equation:   $u_{t} + uu_{x}-\\frac{0.01}{\\pi}u_{xx} = 0$  \n",
        "Boundary Conditions:  \n",
        "$x \\in [-1,1]$  $t \\in [0,1]$  \n",
        "$u(0,x)= -\\sin(\\pi x)$  \n",
        "$u(t,-1)=u(t,1)=0$ "
      ],
      "metadata": {
        "id": "4SRB5FOeGdLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import grad\n",
        "import scipy.io\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "V0U3zeq-Gesa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyDOE    #required for latin hypercube sampling of collocation points\n",
        "from pyDOE import lhs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXX7pyJfIxNR",
        "outputId": "d97f5846-ee4d-4d76-b9a6-1283a0c715e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prepocessing"
      ],
      "metadata": {
        "id": "-YLaI_xz5R5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nu = 0.01/np.pi\n",
        "N_u = 100                                                                       #boundary points\n",
        "N_f = 10000                                                                     #collacation points\n",
        "layers = [2, 25, 25, 25, 25, 25, 25, 25, 25, 1]\n",
        "data = scipy.io.loadmat('burgers_shock.mat')                                    #contains x,t and exact usol\n",
        "t = data['t'].flatten()[:,None]\n",
        "x = data['x'].flatten()[:,None]\n",
        "Exact = np.real(data['usol']).T\n",
        "X, T = np.meshgrid(x,t)\n",
        "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))                  #2 columns containing x,t values\n",
        "u_star = Exact.flatten()[:,None]                                                #1 column containing exact u values \n",
        "lb = X_star.min(0)                                                              #lower & upper bounds for x & t\n",
        "ub = X_star.max(0) \n",
        "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "uu1 = Exact[0:1,:].T\n",
        "xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "uu2 = Exact[:,0:1]\n",
        "xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "uu3 = Exact[:,-1:]\n",
        "\n",
        "X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "X_f_train = lb + (ub-lb)*lhs(2, N_f)                                            #Latin Hypercube Sampling method to generate collacation points\n",
        "X_f_train = np.vstack((X_f_train, X_u_train))\n",
        "u_train = np.vstack([uu1, uu2, uu3])\n",
        "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)                  #Randomly choosing 100 training points\n",
        "X_u_train = X_u_train[idx, :]\n",
        "u_train = u_train[idx,:]\n",
        "\n",
        "X_u = torch.from_numpy(X_u_train[:,0:1]).float()         #x boundary points \n",
        "T_u = torch.from_numpy(X_u_train[:,1:2]).float()         #t boundary points \n",
        "X_f = torch.tensor(X_f_train[:,0:1], requires_grad = True).float()        #x collocation points\n",
        "T_f = torch.tensor(X_f_train[:,1:2], requires_grad = True).float()         #t collocation points\n",
        "u_train = torch.from_numpy(u_train).float()"
      ],
      "metadata": {
        "id": "Yzolo-sMIu1Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PINN (Formulation \\& Implementation)"
      ],
      "metadata": {
        "id": "_zphRfF_5TIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN(nn.Module):\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    super(PINN, self).__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for i, j in zip(layers, layers[1:]):\n",
        "      linear = nn.Linear(i, j)\n",
        "      nn.init.xavier_normal_(linear.weight.data, gain = 1.0)\n",
        "      nn.init.zeros_(linear.bias.data)\n",
        "      self.layers.append(linear)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    L = len(self.layers)\n",
        "    for l, transform in enumerate(self.layers):\n",
        "      if l < L-1:\n",
        "        x = torch.tanh(transform(x))\n",
        "      else:\n",
        "        x = transform(x)\n",
        "    return x  "
      ],
      "metadata": {
        "id": "czFFssyXGeqH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN_Run():\n",
        "\n",
        "  def __init__(self, X_f, T_f, nu, X_u, T_u, model, u_train):\n",
        "    self.X_f = X_f\n",
        "    self.T_f = T_f\n",
        "    self.nu = nu\n",
        "    self.X_u = X_u\n",
        "    self.T_u = T_u\n",
        "    self.u_train = u_train\n",
        "    self.model = model\n",
        "    self.optimizer = torch.optim.LBFGS(\n",
        "            self.model.parameters(), \n",
        "            lr = 1.0, \n",
        "            max_iter=20000, \n",
        "            max_eval=20000, \n",
        "            history_size=40,\n",
        "            tolerance_grad=1e-6, \n",
        "            tolerance_change=1.0 * np.finfo(float).eps,\n",
        "            line_search_fn=\"strong_wolfe\"       \n",
        "        )\n",
        "    self.i = 0\n",
        "\n",
        "  def residual_loss(self):\n",
        "    xf = torch.cat([self.X_f, self.T_f], axis=1)\n",
        "    uf = self.model(xf)\n",
        "    u_x = grad(uf.sum(), self.X_f, retain_graph = True, create_graph = True)[0]\n",
        "    u_xx = grad(u_x.sum(), self.X_f, retain_graph = True, create_graph = True)[0]\n",
        "    u_t = grad(uf.sum(), self.T_f, retain_graph = True, create_graph = True)[0]\n",
        "    f = u_t + uf*u_x - self.nu*u_xx \n",
        "    return torch.mean(torch.square(f))\n",
        "  \n",
        "  def closure(self):\n",
        "    self.model.train()\n",
        "    mse = nn.MSELoss()\n",
        "    self.optimizer.zero_grad()\n",
        "    yhat = self.model(torch.cat([self.X_u, self.T_u], axis=1).float())\n",
        "    loss1 = mse(yhat, self.u_train)\n",
        "    loss2 = self.residual_loss()\n",
        "    loss = loss1 + loss2\n",
        "    loss.backward()\n",
        "    if self.i % 100 == 0:\n",
        "      print('Epoch:', self.i, 'Loss: %.5e' % (loss.item()))\n",
        "    self.i += 1\n",
        "    return loss\n",
        "  \n",
        "  def train_(self):\n",
        "    self.optimizer.step(self.closure)  "
      ],
      "metadata": {
        "id": "jnlrFlqsvBEh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinn_model = PINN(layers)\n",
        "pinn_ = PINN_Run(X_f, T_f, nu, X_u, T_u, pinn_model, u_train)"
      ],
      "metadata": {
        "id": "eXvRxgj8Genz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinn_.train_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kthn4rgrGelk",
        "outputId": "ac32a567-374e-4818-9e0f-e6010514adb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 3.68430e-01\n",
            "Epoch: 100 Loss: 7.57236e-02\n",
            "Epoch: 200 Loss: 4.54286e-02\n",
            "Epoch: 300 Loss: 1.58204e-02\n",
            "Epoch: 400 Loss: 4.87081e-03\n",
            "Epoch: 500 Loss: 1.47870e-03\n",
            "Epoch: 600 Loss: 7.14642e-04\n",
            "Epoch: 700 Loss: 4.53142e-04\n",
            "Epoch: 800 Loss: 3.39726e-04\n",
            "Epoch: 900 Loss: 2.79447e-04\n",
            "Epoch: 1000 Loss: 2.28179e-04\n",
            "Epoch: 1100 Loss: 1.90270e-04\n",
            "Epoch: 1200 Loss: 1.63677e-04\n",
            "Epoch: 1300 Loss: 1.42596e-04\n",
            "Epoch: 1400 Loss: 1.23679e-04\n",
            "Epoch: 1500 Loss: 1.11510e-04\n",
            "Epoch: 1600 Loss: 9.92593e-05\n",
            "Epoch: 1700 Loss: 8.70449e-05\n",
            "Epoch: 1800 Loss: 7.51133e-05\n",
            "Epoch: 1900 Loss: 6.88663e-05\n",
            "Epoch: 2000 Loss: 6.29026e-05\n",
            "Epoch: 2100 Loss: 5.63711e-05\n",
            "Epoch: 2200 Loss: 5.26291e-05\n",
            "Epoch: 2300 Loss: 4.92547e-05\n",
            "Epoch: 2400 Loss: 4.54786e-05\n",
            "Epoch: 2500 Loss: 4.12262e-05\n",
            "Epoch: 2600 Loss: 3.75024e-05\n",
            "Epoch: 2700 Loss: 3.46659e-05\n",
            "Epoch: 2800 Loss: 3.28091e-05\n",
            "Epoch: 2900 Loss: 3.12918e-05\n",
            "Epoch: 3000 Loss: 3.00010e-05\n",
            "Epoch: 3100 Loss: 2.83870e-05\n",
            "Epoch: 3200 Loss: 2.67661e-05\n",
            "Epoch: 3300 Loss: 2.53922e-05\n",
            "Epoch: 3400 Loss: 2.37467e-05\n",
            "Epoch: 3500 Loss: 2.24213e-05\n",
            "Epoch: 3600 Loss: 2.14189e-05\n",
            "Epoch: 3700 Loss: 2.02342e-05\n",
            "Epoch: 3800 Loss: 1.89509e-05\n",
            "Epoch: 3900 Loss: 1.76611e-05\n",
            "Epoch: 4000 Loss: 1.65398e-05\n",
            "Epoch: 4100 Loss: 1.54753e-05\n",
            "Epoch: 4200 Loss: 1.45273e-05\n",
            "Epoch: 4300 Loss: 1.38468e-05\n",
            "Epoch: 4400 Loss: 1.32529e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinn_model.eval()\n",
        "u_pinn = pinn_model(torch.from_numpy(X_star).float())\n",
        "table = np.hstack((u_pinn.detach().numpy(), u_star))\n",
        "print('Predicted   -   Actual')\n",
        "print(table[10010:10020])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMP574UNGefQ",
        "outputId": "1a520649-fa2e-4409-e8a9-2c41c556d204"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted   -   Actual\n",
            "[[0.28538823 0.28533147]\n",
            " [0.2961781  0.29615185]\n",
            " [0.30694997 0.30695429]\n",
            " [0.31770301 0.31773801]\n",
            " [0.32843637 0.32850224]\n",
            " [0.33914948 0.33924619]\n",
            " [0.34984195 0.34996906]\n",
            " [0.36051273 0.36067002]\n",
            " [0.37116086 0.37134826]\n",
            " [0.38178539 0.38200292]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGPeQwU5GedJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbIfeEvwGea8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s41XFxN3GeYe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s35dHLyqGeWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LtuxheE6F7hK"
      },
      "outputs": [],
      "source": []
    }
  ]
}