{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PINNs_PyTorch_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Burgers Equation\n",
        "Equation:   $u_{t} + uu_{x}-\\frac{0.01}{\\pi}u_{xx} = 0$  \n",
        "Boundary Conditions:  \n",
        "$x \\in [-1,1]$  $t \\in [0,1]$  \n",
        "$u(0,x)= -\\sin(\\pi x)$  \n",
        "$u(t,-1)=u(t,1)=0$ "
      ],
      "metadata": {
        "id": "woOYaEA-1z7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "bGpeLJDN6G-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hgQt5sAzxCNz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import grad\n",
        "import scipy.io\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyDOE    #required for latin hypercube sampling of collocation points\n",
        "from pyDOE import lhs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzCTBxuqyMYF",
        "outputId": "1b7c864a-8c0d-413d-a54f-f2775fcda40a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prepocessing"
      ],
      "metadata": {
        "id": "xCuVFPrj6FDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nu = 0.01/np.pi\n",
        "N_u = 100                                                                       #boundary points\n",
        "N_f = 10000                                                                     #collacation points\n",
        "layers = [2, 25, 25, 25, 25, 25, 25, 25, 25, 1]\n",
        "data = scipy.io.loadmat('burgers_shock.mat')                                    #contains x,t and exact usol\n",
        "t = data['t'].flatten()[:,None]\n",
        "x = data['x'].flatten()[:,None]\n",
        "Exact = np.real(data['usol']).T\n",
        "X, T = np.meshgrid(x,t)\n",
        "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))                  #2 columns containing x,t values\n",
        "u_star = Exact.flatten()[:,None]                                                #1 column containing exact u values \n",
        "lb = X_star.min(0)                                                              #lower & upper bounds for x & t\n",
        "ub = X_star.max(0) \n",
        "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "uu1 = Exact[0:1,:].T\n",
        "xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "uu2 = Exact[:,0:1]\n",
        "xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "uu3 = Exact[:,-1:]\n",
        "\n",
        "X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "X_f_train = lb + (ub-lb)*lhs(2, N_f)                                            #Latin Hypercube Sampling method to generate collacation points\n",
        "X_f_train = np.vstack((X_f_train, X_u_train))\n",
        "u_train = np.vstack([uu1, uu2, uu3])\n",
        "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)                  #Randomly choosing 100 training points\n",
        "X_u_train = X_u_train[idx, :]\n",
        "u_train = u_train[idx,:]\n",
        "\n",
        "X_u = torch.from_numpy(X_u_train[:,0:1]).float()         #x boundary points \n",
        "T_u = torch.from_numpy(X_u_train[:,1:2]).float()         #t boundary points \n",
        "X_f = torch.tensor(X_f_train[:,0:1], requires_grad = True).float()        #x collocation points\n",
        "T_f = torch.tensor(X_f_train[:,1:2], requires_grad = True).float()         #t collocation points\n",
        "u_train = torch.from_numpy(u_train).float()"
      ],
      "metadata": {
        "id": "IZGaRhiZyMVi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "\n",
        "  def __init__(self, X_u, T_u, u_train):\n",
        "    self.x = torch.cat([X_u, T_u], axis=1).float()\n",
        "    self.y = u_train\n",
        "    self.len = u_train.shape[0]\n",
        "  \n",
        "  def __getitem__(self, index):    \n",
        "      return self.x[index], self.y[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "      return self.len"
      ],
      "metadata": {
        "id": "azkK1GuzwjBi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Data(X_u, T_u, u_train)\n",
        "train_loader = DataLoader(dataset=data_set, batch_size=50)"
      ],
      "metadata": {
        "id": "DwZQKVH6yumB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Burger's Equation PINN (Formulation & Implementation)"
      ],
      "metadata": {
        "id": "ABSO1Bnu6Nrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN(nn.Module):\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    super(PINN, self).__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for i, j in zip(layers, layers[1:]):\n",
        "      linear = nn.Linear(i, j)\n",
        "      nn.init.xavier_normal_(linear.weight.data, gain = 1.0)\n",
        "      nn.init.zeros_(linear.bias.data)\n",
        "      self.layers.append(linear)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    L = len(self.layers)\n",
        "    for l, transform in enumerate(self.layers):\n",
        "      if l < L-1:\n",
        "        x = torch.tanh(transform(x))\n",
        "      else:\n",
        "        x = transform(x)\n",
        "    return x   "
      ],
      "metadata": {
        "id": "MvSE3vGnyMTK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_loss(X_f, T_f, model, nu):\n",
        "  xf = torch.cat([X_f, T_f], axis=1)\n",
        "  uf = model(xf)\n",
        "  u_x = grad(uf.sum(), X_f, retain_graph = True, create_graph = True)[0]\n",
        "  u_xx = grad(u_x.sum(), X_f, retain_graph = True, create_graph = True)[0]\n",
        "  u_t = grad(uf.sum(), T_f, retain_graph = True, create_graph = True)[0]\n",
        "  f = u_t + uf*u_x - nu*u_xx \n",
        "  return torch.mean(torch.square(f))"
      ],
      "metadata": {
        "id": "kQFpzrKtyMRB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PINN_train(model, train_loader, optimizer, X_f, T_f, nu):\n",
        "  epochs = 20000\n",
        "  mse = nn.MSELoss()\n",
        "  for epoch in range(epochs):\n",
        "    for x, y in train_loader:\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      yhat = model(x)\n",
        "      loss1 = mse(yhat, y)\n",
        "      loss2 = residual_loss(X_f, T_f, model, nu)\n",
        "      loss = loss1 + loss2\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch:', epoch, 'Loss: %.5e' % (loss.item()))\n",
        "  return"
      ],
      "metadata": {
        "id": "ADXuvrHIyMOR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinn_model = PINN(layers)\n",
        "optimizer = torch.optim.Adam(pinn_model.parameters(), lr = 1e-4)"
      ],
      "metadata": {
        "id": "FBXlmkCiyMIq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINN_train(pinn_model, train_loader, optimizer, X_f, T_f, nu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq4krrTUyMHH",
        "outputId": "7ae77e38-61cd-4492-adb1-be6a5e5451ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 2.46112e-01\n",
            "Epoch: 500 Loss: 8.32914e-02\n",
            "Epoch: 1000 Loss: 7.17834e-02\n",
            "Epoch: 1500 Loss: 6.05222e-02\n",
            "Epoch: 2000 Loss: 5.23553e-02\n",
            "Epoch: 2500 Loss: 4.56048e-02\n",
            "Epoch: 3000 Loss: 4.17674e-02\n",
            "Epoch: 3500 Loss: 3.60842e-02\n",
            "Epoch: 4000 Loss: 1.25536e-02\n",
            "Epoch: 4500 Loss: 6.54742e-03\n",
            "Epoch: 5000 Loss: 4.41096e-03\n",
            "Epoch: 5500 Loss: 3.42569e-03\n",
            "Epoch: 6000 Loss: 2.41042e-03\n",
            "Epoch: 6500 Loss: 2.05730e-03\n",
            "Epoch: 7000 Loss: 1.83030e-03\n",
            "Epoch: 7500 Loss: 1.83090e-03\n",
            "Epoch: 8000 Loss: 1.13324e-03\n",
            "Epoch: 8500 Loss: 8.94912e-04\n",
            "Epoch: 9000 Loss: 7.82691e-04\n",
            "Epoch: 9500 Loss: 7.07575e-04\n",
            "Epoch: 10000 Loss: 6.21982e-04\n",
            "Epoch: 10500 Loss: 5.55963e-04\n",
            "Epoch: 11000 Loss: 5.41247e-04\n",
            "Epoch: 11500 Loss: 4.82224e-04\n",
            "Epoch: 12000 Loss: 4.23994e-04\n",
            "Epoch: 12500 Loss: 4.03897e-04\n",
            "Epoch: 13000 Loss: 3.71028e-04\n",
            "Epoch: 13500 Loss: 4.27452e-04\n",
            "Epoch: 14000 Loss: 3.21217e-04\n",
            "Epoch: 14500 Loss: 3.82691e-04\n",
            "Epoch: 15000 Loss: 2.85728e-04\n",
            "Epoch: 15500 Loss: 3.72869e-04\n",
            "Epoch: 16000 Loss: 2.64862e-04\n",
            "Epoch: 16500 Loss: 2.81801e-04\n",
            "Epoch: 17000 Loss: 2.73616e-04\n",
            "Epoch: 17500 Loss: 2.21257e-04\n",
            "Epoch: 18000 Loss: 2.21606e-04\n",
            "Epoch: 18500 Loss: 2.04484e-04\n",
            "Epoch: 19000 Loss: 1.94666e-04\n",
            "Epoch: 19500 Loss: 1.90780e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinn_model.eval()\n",
        "u_pinn = pinn_model(torch.from_numpy(X_star).float())\n",
        "table = np.hstack((u_pinn.detach().numpy(), u_star))\n",
        "print('Predicted   -   Actual')\n",
        "print(table[10010:10020])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOOS8rPAyMFM",
        "outputId": "e83ea292-8668-4077-cd74-e6f546891380"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted   -   Actual\n",
            "[[0.28493625 0.28533147]\n",
            " [0.29575807 0.29615185]\n",
            " [0.30656067 0.30695429]\n",
            " [0.3173413  0.31773801]\n",
            " [0.32810009 0.32850224]\n",
            " [0.33883479 0.33924619]\n",
            " [0.34954569 0.34996906]\n",
            " [0.36023    0.36067002]\n",
            " [0.37088776 0.37134826]\n",
            " [0.38151738 0.38200292]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WuD_ydr7yMC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7m5OFpWyMAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}